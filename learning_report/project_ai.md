# Artificial Inference (AI)

Chat GPT is all the rage nowadays. Its responses to prompts are eerily similar to human responses. However, like most technological advancements, it's not magic. Generative models are simply given a very large body of texts and their primary job is to answer the following question: "From all the text I've seen, which word has the highest probability to come after the user's question". Critics of such systems have therefore named systems like these "Stochastic parrots". And these stochastic parrots only know what has been presented to them in their training data. Now their training data, although huge, can not contain complete information about everything. Therefore, these models sometimes tell us things based on very limited data a.k.a "These systems hallucinate". That's all nice and dandy but what does this have to do with ISP?

## Humans also hallucinate
Throughout this course, I learned that we as humans are also prone to hallucination. Whenever we were brainstorming ideas, I noticed that everyone's ideas were informed by their own limited set of "training data". Like Chat-GPT, no one knows everything, so we often hallucinate about what works and what doesn't work. This is where the primary tenent of this course, "Validation", comes into the picture. Prima facie it seems like a simple idea but it requires a lot of effort and deliberate practice.

## What did I learn about validation?
There were two main "learning opportunities" that we experienced during the course:


